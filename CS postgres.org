#+TITLE: CS postgres
#+DESCRIPTION:
#+KEYWORDS: postgres, db, CS
#+STARTUP:  content


- [[wiki:index][Index]]

- Parent: [[wiki:CS Technical][CS Technical]]

- Related:

* To read
- [ ] https://www.crunchydata.com/blog/postgres-data-flow
- [ ] https://www.2ndquadrant.com/en/blog/postgresql-12-foreign-keys-and-partitioned-tables/
- [ ] https://medium.com/geekculture/postgres-brin-index-large-data-performance-with-minimal-storage-4db6b9f64ca4
- [ ] https://dzone.com/articles/is-your-postgres-query-starved-for-memory
- [ ] https://pgconf.ru/en/2020/271827
- [ ] https://vadosware.io/post/everything-ive-seen-on-optimizing-postgres-on-zfs-on-linux/#zfs-tunables

* CS postgres

** Wipe database data for user
#+BEGIN_SRC sql
DROP owned BY <user>;
#+END_SRC

** Get various sizes
- Get table size
#+BEGIN_SRC sql
SELECT pg_size_pretty( pg_total_relation_size(tablename') );
#+END_SRC
- Get database size
#+BEGIN_SRC sql
SELECT pg_size_pretty( pg_database_size(‘databname‘) );
#+END_SRC
** Performance

*** Get info on postgres ops
#+BEGIN_SRC sql
SELECT * FROM pg_stat_statements ORDER BY max_plan_time DESC LIMIT 5;
SELECT * FROM pg_stat_statements ORDER BY max_exec_time DESC LIMIT 5;
#+END_SRC
#+BEGIN_SRC
SELECT query, calls, total_exec_time, rows, 100.0 * shared_blks_hit/nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 5;
#+END_SRC

*** Check query performance
#+BEGIN_SRC sql
EXPLAIN ANALYZE SELECT 1+1;
#+END_SRC

*** Check if we hit max connnections
Straighforward
#+BEGIN_SRC sql
SELECT count(*) FROM pg_stat_activity;
#+END_SRC
By state
#+BEGIN_SRC sql
SELECT state, count(*) FROM pg_stat_activity GROUP BY state;
#+END_SRC

*** Connections in lock
#+BEGIN_SRC sql
SELECT count(distinct pid) FROM pg_locks WHERE granted = false;
#+END_SRC

*** Maximum transaction age
#+BEGIN_SRC sql
SELECT max(now() - xact_start) FROM pg_stat_activity
    WHERE state IN ('idle in transaction', 'active');
#+END_SRC

*** Show parallel settings for Postgres
#+BEGIN_SRC sql
SELECT name, setting,unit FROM pg_settings
  WHERE name LIKE '%parallel%';
#+END_SRC
#+BEGIN_SRC text
| name                            | setting | unit |
|---------------------------------+---------+------|
| force_parallel_mode             |     off |      |
| max_parallel_workers            |       8 |      |
| max_parallel_workers_per_gather |       2 |      |
| min_parallel_index_scan_size    |      64 | 8kB  |
| min_parallel_table_scan_size    |    1024 | 8kB  |
| parallel_setup_cost          by |    1000 |      |
| parallel_tuple_cost             |     0.1 |      |
#+END_SRC


** Operations not requiring exclusive accesses or long locks
1. ADD COLUMN
2. SET DEFAULT
3. SET NOT NULL
4. RENAME COLUMN
5. ALTER COLUMN a TYPE varchar(30);
6. DROP COLUMN
** Ease up Postgres locking when needed
*** Add constraint
Basic approach has serious issues, it will require exclusive access to table
#+BEGIN_SRC sql
  ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (column_name > 1);
#+END_SRC
Can be re-done as follows. Will not require to check existing entries, only be
applied to new ones.
#+BEGIN_SRC sql
  ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (column_name > 1) NOT VALID;
#+END_SRC
And later validation can be done with separate instruction:
#+BEGIN_SRC sql
  ALTER TABLE table_name VALIDATE CONSTRAINT constraint_name;
#+END_SRC
*** Add unique column
Original approach will require lock while bulding index under UNIQUE
#+BEGIN_SRC sql
  ALTER TABLE table_name ADD COLUMNT column_name UNIQUE;
#+END_SRC
Can be redone as two operations, creating index concurrently and using created
index for column:
#+BEGIN_SRC sql
  CREATE UNIQUE INDEX CONCURRENTLY index_name ON table_name(column_name);
  ALTER TABLE table_name ADD CONSTRAINT constraint_name UNIQUE USING INDEX index_name;
#+END_SRC
*** Change column type
Chaning column type will require table rewrite and probably index rebuild,
original approach:
#+BEGIN_SRC sql
  ALTER TABLE table_name ALTER COLUMN column_name TYPE type USING(...);
#+END_SRC
Changed approach, add additional column with proper type, create trigger to
write also to new column, copy data from old column to new, delete old column,
rename new to old:
#+BEGIN_SRC sql
  ALTER TABLE table_name ADD COLUMN column_name_new type;
  CREATE TRIGGER trigger_name
   AFTER INSERT OR UPDATE ON table_name
   FOR EACH ROW
   BEGIN
   ...
   END;
  UPDATE table_name SET ...;

  BEGIN;
  DELETE TRIGGER trigger_name;
  ALTER TABLE table_name DROP COLUMN column_name;
  ALTER TABLE table_name RENAME column_name_new TO column_name;
  COMMIT;
#+END_SRC
*** Add new column with default
Adding new column with some preset value will require to update ALL rows in
table, thus requiring extensive access to table.
Original approach:
#+BEGIN_SRC sql
  ALTER TABLE table_name ADD COLUMN column_name INTEGER DEFAULT -1 NOT NULL;
#+END_SRC
Can be redone as creating column first, then setting default, then updating old
entries then adding not null.
#+BEGIN_SRC sql
  BEGIN;
  ALTER TABLE table_name ADD COLUMN column_name INTEGER;
  ALTER TABLE table_name ALTER COLUMN column_name SET DEFAULT -1;
  COMMIT;

  UPDATE table_name SET column_name = -1 WHERE id IN (SELECT id FROM table_name WHERE column_name IS NULL LIMIT 10000);
  ALTER TABLE table_name ALTER COLUMN column_name SET NOT NULL;
#+END_SRC

** Partitions
*** Get all partitions for table
#+BEGIN_SRC sql
SELECT
  child.relname
FROM pg_inherits
  JOIN pg_class parent ON pg_inherits.inhparent = parent.oid
  JOIN pg_class child ON pg_inherits.inhrelid = child.oid
  JOIN pg_namespace nmsp_parent ON nmsp_parent.oid = parent.relnamespace
  JOIN pg_namespace nmsp_child  ON nmsp_child.oid = child.relnamespace
WHERE parent.relname='partitioned_table_name';
#+END_SRC

*** Pathman
**** Show pathman partitions
#+BEGIN_SRC sql
SELECT show_partition_list();
#+END_SRC
**** Show pg_pathman/partitioning cache stats
#+BEGIN_SRC sql
SELECT show_cache_stats();
#+END_SRC

** SQL language
*** Alter table, add column
#+BEGIN_SRC sql
ALTER TABLE sometable ADD COLUMN somecolumn CHARACTER VARYING(40);
#+END_SRC
*** Alter table, add default
#+BEGIN_SRC sql
ALTER TABLE sometable ALTER COLUMN somecolumn SET DEFAULT 'started';
#+END_SRC
*** Generate table name in loop
#+BEGIN_SRC sql
DO
$$
BEGIN
FOR counter IN 0..64 LOOP
RAISE NOTICE 'Index: %', counter;
EXECUTE format('delete from %I', 'table_1_' || counter);
EXECUTE format('delete from %I', 'table_2_' || counter);
EXECUTE format('delete from %I', 'table_3_' || counter);
END LOOP;
END;
$$ LANGUAGE plpgsql;
#+END_SRC
*** Print result of execute
#+BEGIN_SRC sql
DO
$$
DECLARE
rec record;
BEGIN
EXECUTE format('select somecolumn from sometable where id = 93449692274348053')
INTO rec;
RAISE NOTICE 'result: %', rec;
END;
$$ LANGUAGE plpgsql;
#+END_SRC

*** Select in loop(by shards) and output select results as it goes
#+BEGIN_SRC sql
DO
$$
DECLARE
  query TEXT;
  result RECORD;
BEGIN
FOR counter IN 0..1 LOOP
  RAISE NOTICE 'Index: %', counter;
  query := format('select count(1), groupcolumn from some_sharded_table_' || counter || ' group by groupcolumn');
  FOR result IN EXECUTE query
    LOOP
      RAISE NOTICE '%', result;
    END LOOP;
END LOOP;
END;
$$ LANGUAGE plpgsql;
#+END_SRC

*** Get 2 datetimes sequentially, get their diff, raise notice if diff != 0
#+BEGIN_SRC sql
DO
$$
DECLARE
rec1 RECORD;
rec2 RECORD;
rec3 RECORD;
query TEXT;
BEGIN
  query := format('SELECT timezone(''UTC''::text, now())');
  FOR counter IN 0..100000 LOOP
    EXECUTE query INTO rec1;
    EXECUTE query INTO rec2;
    EXECUTE format('SELECT ''%s''::TIMESTAMP - ''%s''::TIMESTAMP AS diff', rec1.timezone, rec2.timezone) INTO rec3;
    IF rec3.diff != '00:00:00' THEN
      RAISE NOTICE '%', rec3.diff;
    END IF;
  END LOOP;
END;
$$ LANGUAGE plpgsql;
#+END_SRC

*** Postgres SQL operators
| Operator   | Meaning                           | Example                                           | Result                    |
|------------+-----------------------------------+---------------------------------------------------+---------------------------|
| \=         | equal                             | ARRAY[1.1,2.1,3.1]::int[] = ARRAY[1,2,3]          | t                         |
| \<\>       | not equal                         | ARRAY[1,2,3] <> ARRAY[1,2,4]                      | t                         |
| <          | less than                         | ARRAY[1,2,3] < ARRAY[1,2,4]                       | t                         |
| >          | greater than                      | ARRAY[1,4,3] > ARRAY[1,2,4]                       | t                         |
| <=         | less than or equal                | ARRAY[1,2,3] <= ARRAY[1,2,3]                      | t                         |
|            |                                   |                                                   |                           |
| >=         | greater than or equal             | ARRAY[1,4,3] >= ARRAY[1,4,3]                      | t                         |
|            |                                   |                                                   |                           |
| @>         | contains                          | ARRAY[1,4,3] @> ARRAY[3,1]                        | t                         |
|            |                                   |                                                   |                           |
| <@         | is contained by                   | ARRAY[2,7] <@ ARRAY[1,7,4,2,6]                    | t                         |
|            |                                   |                                                   |                           |
| &&         | overlap (have elements in common) | ARRAY[1,4,3] && ARRAY[2,1]                        | t                         |
| \vert\vert | array-to-array concatenation      | ARRAY[1,2,3]  \vert\vert ARRAY[4,5,6]             | {1,2,3,4,5,6}             |
| \vert\vert | array-to-array   concatenation    | ARRAY[1,2,3] \vert\vert ARRAY[ [4,5,6], [7,8,9] ] | {{1,2,3},{4,5,6},{7,8,9}} |
| \vert\vert | element-to-array concatenation    | 3 \vert\vert ARRAY[4,5,6]                         | {3,4,5,6}                 |
| \vert\vert | array-to-element concatenation    | ARRAY[4,5,6] \vert\vert 7                         | {4,5,6,7}                 |

*** Count transactions per user
#+BEGIN_SRC sql
SELECT somegroupcolumn, COUNT(anothercolumn) FROM sometable GROUP BY somegroupcolumn;
#+END_SRC

*** Get non-empty arrays
#+BEGIN_SRC sql
SELECT tags FROM item WHERE array_length(tags, 1) != 0;
#+END_SRC

*** Check if arrays overlaps
#+BEGIN_SRC sql
SELECT NOT '{1,2}'::integer[] && '{1}'::integer[];
#+END_SRC

*** Copy table data to CSV
#+BEGIN_SRC sql
\copy (SELECT t2.somecolumn, t1.somecolumn FROM sometable t1 LEFT JOIN anothertable t2 ON t2.id = t1.anothertable_id WHERE array_length(t1.somecolumn, 1) != 0) TO '/tmp/output.csv' CSV HEADER DELIMITER E'\t';
#+END_SRC

*** Query json object
#+BEGIN_SRC sql
select * from sometable where timecolumn > '2023-03-01 00:00:00' and timecolumn < '2023-03-02 00:00:00' and jsoncolumn -> 'memo' ->> 'eventID' in ('231202', '231203', '231204', '231205');
#+END_SRC
*** Query json object, see that key exists
#+BEGIN_SRC sql
select * from sometable where jsoncolumn is not null and meta_data::jsonb ? 'key_in_json';
#+END_SRC
*** Sort entries by number of columns for each distinct column, sort by number of entries per distinct
#+BEGIN_SRC sql
SELECT t1.groupcolumn, array_length(array_agg(t1.somecolumn), 1) AS al FROM sometable t1 GROUP BY t1.groupcolumn ORDER BY al DESC;
#+END_SRC
*** Partial postgres restore
#+BEGIN_SRC sh
# Create table content of a backup, with only $table_name in it
pg_restore -l $path_to_backup  | grep $table_name > table_content.txt
# Restore only tables listed in table_content.txt, -j 8 parallelize process
pg_restore -j 8 -U $dbuser -h $dbhost -L  table_content.txt --dbname=$dbname --clean -Fd -v $path_to_backup
#+END_SRC
*** Join on array column
#+BEGIN_SRC sql
SELECT count(id), array_agg FROM (
  SELECT td.id, array_agg(n.key) FROM {table_name} td
  LEFT JOIN namespace n ON n.id = ANY(td.namespaces)
  GROUP BY td.id, n.id
) X GROUP BY array_agg order by count DESC
#+END_SRC
*** Get all entries that have more then one entry with regards to one column and distinct values in another
#+BEGIN_SRC sql
 SELECT trx_id FROM tablename GROUP BY some_parent_id HAVING COUNT(DISTINCT table_id) > 1 AND COUNT(DISTINCT some_value_field) > 1;
#+END_SRC
